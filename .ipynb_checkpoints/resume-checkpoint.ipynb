{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f15b909-c269-46a7-bfd7-f9a382ffa6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install pandas numpy scikit-learn nltk flask PyPDF2\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Install Required Libraries\n",
    "\"\"\"\n",
    "!pip install pandas numpy scikit-learn nltk flask PyPDF2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db9b47f8-1859-42c3-a493-cacad2551d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\NAVYA\n",
      "[nltk_data]     SAI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa33b3af-6288-4a65-8f27-d4d2d6577071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Skill Database and Keywords\n",
    "SKILL_DB = [\n",
    "    \"python\", \"java\", \"c\", \"c++\", \"html\", \"css\", \"javascript\",\n",
    "    \"machine learning\", \"deep learning\", \"sql\", \"mongodb\",\n",
    "    \"react\", \"node\", \"data analysis\", \"nlp\", \"ai\", \"ml\",\n",
    "    \"tensorflow\", \"pytorch\", \"docker\", \"kubernetes\", \"aws\",\n",
    "    \"azure\", \"git\", \"flask\", \"django\", \"fastapi\", \"pandas\",\n",
    "    \"numpy\", \"scikit-learn\", \"data science\", \"analytics\"\n",
    "]\n",
    "\n",
    "EXPERIENCE_KEYWORDS = [\n",
    "    \"developed\", \"managed\", \"led\", \"created\", \"designed\",\n",
    "    \"implemented\", \"built\", \"architected\", \"optimized\",\n",
    "    \"years of experience\", \"work experience\", \"internship\"\n",
    "]\n",
    "\n",
    "PROJECT_KEYWORDS = [\n",
    "    \"project\", \"portfolio\", \"built\", \"created\", \"developed\",\n",
    "    \"implemented\", \"designed\", \"application\", \"system\", \"website\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "583f67d1-d4b2-4fc7-a2c8-116f4f72da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create Custom Resume Dataset\n",
    "def create_resume_dataset():\n",
    "    \"\"\"Create a custom resume dataset with IT and Marketing profiles\"\"\"\n",
    "    \n",
    "    resumes = [\n",
    "        # IT Resumes\n",
    "        \"Python developer with 5 years experience in machine learning and deep learning. Skilled in TensorFlow, PyTorch, scikit-learn. Built multiple AI projects including NLP chatbots.\",\n",
    "        \"Full stack developer proficient in JavaScript, React, Node.js, MongoDB. Developed 10+ web applications. Experience with HTML, CSS, and REST APIs.\",\n",
    "        \"Data scientist with expertise in Python, SQL, data analysis, and machine learning. Created predictive models using scikit-learn and pandas. Strong analytical skills.\",\n",
    "        \"Software engineer specializing in Java, C++, and Python. Led development of distributed systems. Experience with Docker, Kubernetes, and cloud platforms AWS.\",\n",
    "        \"AI/ML engineer with deep learning expertise. Implemented computer vision projects using TensorFlow and PyTorch. Skilled in NLP and data preprocessing.\",\n",
    "        \"Backend developer with Node.js, Python Flask, FastAPI experience. Built scalable REST APIs. Proficient in SQL and MongoDB databases.\",\n",
    "        \"Web developer skilled in HTML, CSS, JavaScript, React. Created responsive websites. Experience with Git version control and agile methodologies.\",\n",
    "        \"Data analyst with SQL, Python, and data visualization skills. Performed statistical analysis. Created dashboards using pandas and numpy.\",\n",
    "        \n",
    "        # Marketing Resumes\n",
    "        \"Marketing manager with 7 years experience in digital marketing campaigns. Expert in SEO, SEM, social media marketing. Increased brand awareness by 300%.\",\n",
    "        \"Content marketing specialist skilled in copywriting, content strategy, and social media management. Created engaging campaigns across multiple platforms.\",\n",
    "        \"Brand manager with expertise in market research, consumer behavior analysis. Led successful product launches and rebranding initiatives.\",\n",
    "        \"Digital marketing expert proficient in Google Ads, Facebook advertising, email marketing. Generated high ROI campaigns with data-driven strategies.\",\n",
    "        \"Social media manager experienced in community management, influencer partnerships. Grew follower base by 500% through creative campaigns.\",\n",
    "        \"Marketing analyst with strong analytical skills in market segmentation and competitive analysis. Used Excel and analytics tools for insights.\",\n",
    "        \"Public relations specialist skilled in media relations, press release writing. Built strong relationships with journalists and media outlets.\",\n",
    "        \"Product marketing manager with B2B and B2C experience. Developed go-to-market strategies and positioning for new products.\"\n",
    "    ]\n",
    "    \n",
    "    labels = ['IT'] * 8 + ['Marketing'] * 8\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'resume': resumes,\n",
    "        'label': labels\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6e3066c-0bdd-45ea-84a9-74426e8fb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Skill Extraction Function\n",
    "def extract_skills(text):\n",
    "    \"\"\"Extract skills from resume text\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    found_skills = []\n",
    "    \n",
    "    for skill in SKILL_DB:\n",
    "        if skill.lower() in text_lower:\n",
    "            found_skills.append(skill)\n",
    "    \n",
    "    return found_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b5c7428-bc07-432a-b448-750adaba2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Experience Detection\n",
    "def detect_experience(text):\n",
    "    \"\"\"Detect experience mentions in resume\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    experience_count = 0\n",
    "    \n",
    "    for keyword in EXPERIENCE_KEYWORDS:\n",
    "        if keyword in text_lower:\n",
    "            experience_count += 1\n",
    "    \n",
    "    # Extract years of experience\n",
    "    years_pattern = r'(\\d+)\\s*(?:years?|yrs?)(?:\\s+of)?\\s+(?:experience|exp)'\n",
    "    years_match = re.search(years_pattern, text_lower)\n",
    "    years = int(years_match.group(1)) if years_match else 0\n",
    "    \n",
    "    return {\n",
    "        'experience_keywords': experience_count,\n",
    "        'years': years\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3b9b1a4-28a6-4bd5-96a1-fe213282f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Project Detection\n",
    "def detect_projects(text):\n",
    "    \"\"\"Detect project mentions in resume\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    project_count = 0\n",
    "    \n",
    "    for keyword in PROJECT_KEYWORDS:\n",
    "        if keyword in text_lower:\n",
    "            project_count += 1\n",
    "    \n",
    "    return project_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e698671-bf19-4c6a-b348-ca434dd85aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Calculate Fit Score\n",
    "def calculate_fit_score(resume_text, job_description):\n",
    "    \"\"\"Calculate fit score based on multiple factors\"\"\"\n",
    "    \n",
    "    # Extract skills\n",
    "    resume_skills = set(extract_skills(resume_text))\n",
    "    job_skills = set(extract_skills(job_description))\n",
    "    \n",
    "    # Skill match score (40%)\n",
    "    if len(job_skills) > 0:\n",
    "        skill_match = len(resume_skills.intersection(job_skills)) / len(job_skills)\n",
    "    else:\n",
    "        skill_match = 0\n",
    "    \n",
    "    # Experience score (30%)\n",
    "    exp_data = detect_experience(resume_text)\n",
    "    exp_score = min(exp_data['years'] / 10, 1.0) * 0.5 + min(exp_data['experience_keywords'] / 5, 1.0) * 0.5\n",
    "    \n",
    "    # Project score (30%)\n",
    "    project_count = detect_projects(resume_text)\n",
    "    project_score = min(project_count / 5, 1.0)\n",
    "    \n",
    "    # Weighted total\n",
    "    fit_score = (skill_match * 0.4 + exp_score * 0.3 + project_score * 0.3) * 100\n",
    "    \n",
    "    return {\n",
    "        'fit_score': round(fit_score, 2),\n",
    "        'matched_skills': list(resume_skills.intersection(job_skills)),\n",
    "        'total_skills': list(resume_skills),\n",
    "        'experience_years': exp_data['years'],\n",
    "        'project_count': project_count\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a7c3efb-7d0b-4c7d-a5ff-cfd3e23baa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating resume dataset...\n",
      "Dataset created with 16 resumes\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "IT           8\n",
      "Marketing    8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample resume:\n",
      "Python developer with 5 years experience in machine learning and deep learning. Skilled in TensorFlow, PyTorch, scikit-learn. Built multiple AI projects including NLP chatbots....\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Load and Prepare Dataset\n",
    "print(\"Creating resume dataset...\")\n",
    "df = create_resume_dataset()\n",
    "print(f\"Dataset created with {len(df)} resumes\")\n",
    "print(f\"\\nLabel distribution:\\n{df['label'].value_counts()}\")\n",
    "print(f\"\\nSample resume:\\n{df['resume'].iloc[0][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9000826a-cfc6-4748-96d1-3596ba987dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing and extracting features...\n",
      "Feature matrix shape: (16, 100)\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Text Preprocessing and Feature Extraction\n",
    "print(\"\\nPreprocessing and extracting features...\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(df['resume'])\n",
    "y = df['label']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db34c55d-955f-4170-90f7-72be40cacee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 11\n",
      "Test set size: 5\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1c815e2-3e58-4200-93ea-9fcc43a519ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression model...\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Model Training\n",
    "print(\"\\nTraining Logistic Regression model...\")\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b2003f9-02d5-41c1-8e96-3a3a2d747245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 80.00%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 1]\n",
      " [0 2]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IT       1.00      0.67      0.80         3\n",
      "   Marketing       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Model Evaluation\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd878207-541e-47ac-b8bd-8c6f907e973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model and vectorizer...\n",
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Save Model and Vectorizer\n",
    "print(\"\\nSaving model and vectorizer...\")\n",
    "\n",
    "with open('resume_classifier_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b57eda7-88b1-4146-931c-0085adf7ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Test the Complete System\n",
    "def analyze_resume(resume_text, job_description):\n",
    "    \"\"\"Complete analysis of a resume against a job description\"\"\"\n",
    "    \n",
    "    # Predict category\n",
    "    resume_vector = tfidf_vectorizer.transform([resume_text])\n",
    "    category = model.predict(resume_vector)[0]\n",
    "    category_prob = model.predict_proba(resume_vector)[0]\n",
    "    \n",
    "    # Calculate fit score\n",
    "    fit_data = calculate_fit_score(resume_text, job_description)\n",
    "    \n",
    "    return {\n",
    "        'category': category,\n",
    "        'category_confidence': round(max(category_prob) * 100, 2),\n",
    "        'fit_score': fit_data['fit_score'],\n",
    "        'matched_skills': fit_data['matched_skills'],\n",
    "        'total_skills': fit_data['total_skills'],\n",
    "        'experience_years': fit_data['experience_years'],\n",
    "        'project_count': fit_data['project_count']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d99dc13e-7f04-4199-b6ce-373d33218a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEMO: Resume Analysis\n",
      "============================================================\n",
      "\n",
      "Category: IT\n",
      "Category Confidence: 58.09%\n",
      "Fit Score: 73.0%\n",
      "\n",
      "Matched Skills: fastapi, nlp, c, scikit-learn, sql, flask, machine learning, tensorflow, python\n",
      "All Skills Found: fastapi, nlp, deep learning, pytorch, ai, numpy, tensorflow, c, ml, pandas, scikit-learn, sql, flask, machine learning, data analysis, python\n",
      "Experience: 6 years\n",
      "Projects Mentioned: 3\n",
      "\n",
      "============================================================\n",
      "Setup complete! Ready for Flask application.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Demo Analysis\n",
    "sample_resume = \"\"\"\n",
    "Senior Python Developer with 6 years of experience in machine learning and AI. \n",
    "Expert in deep learning frameworks like TensorFlow and PyTorch. Built 15+ ML projects \n",
    "including NLP chatbots and computer vision systems. Proficient in data analysis using \n",
    "pandas, numpy, and scikit-learn. Strong experience with Flask, FastAPI, and SQL databases.\n",
    "\"\"\"\n",
    "\n",
    "sample_job = \"\"\"\n",
    "Looking for Python developer with machine learning experience. Must know TensorFlow, \n",
    "scikit-learn, and NLP. Experience with Flask or FastAPI required. SQL knowledge preferred.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEMO: Resume Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = analyze_resume(sample_resume, sample_job)\n",
    "\n",
    "print(f\"\\nCategory: {result['category']}\")\n",
    "print(f\"Category Confidence: {result['category_confidence']}%\")\n",
    "print(f\"Fit Score: {result['fit_score']}%\")\n",
    "print(f\"\\nMatched Skills: {', '.join(result['matched_skills'])}\")\n",
    "print(f\"All Skills Found: {', '.join(result['total_skills'])}\")\n",
    "print(f\"Experience: {result['experience_years']} years\")\n",
    "print(f\"Projects Mentioned: {result['project_count']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Setup complete! Ready for Flask application.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ee9bbd-bbb1-4a74-ac05-9258bba42623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in C:/Users/NAVYA SAI/automated-resume-screening/.git/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of '.ipynb_checkpoints/app-checkpoint.py', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of '.ipynb_checkpoints/resume-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'app.py', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'resume.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'templates/.ipynb_checkpoints/index-checkpoint.html', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'templates/index.html', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main (root-commit) c79eae5] first commit\n",
      " 8 files changed, 2686 insertions(+)\n",
      " create mode 100644 .ipynb_checkpoints/app-checkpoint.py\n",
      " create mode 100644 .ipynb_checkpoints/resume-checkpoint.ipynb\n",
      " create mode 100644 app.py\n",
      " create mode 100644 resume.ipynb\n",
      " create mode 100644 resume_classifier_model.pkl\n",
      " create mode 100644 templates/.ipynb_checkpoints/index-checkpoint.html\n",
      " create mode 100644 templates/index.html\n",
      " create mode 100644 tfidf_vectorizer.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: remote origin already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Navya032006/Automated-Resume-Screening.git\n",
      " * [new branch]      main -> main\n"
     ]
    }
   ],
   "source": [
    "!git init\n",
    "!git add .\n",
    "!git commit -m \"first commit\"\n",
    "!git branch -M main\n",
    "!git remote add origin https://github.com/Navya032006/Automated-Resume-Screening.git\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2f061a-af8b-4314-a7e3-69095651f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'requirements.txt', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main d9f6ce4] Add requirements for resume screening app\n",
      " 1 file changed, 8 insertions(+)\n",
      " create mode 100644 requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Navya032006/Automated-Resume-Screening.git\n",
      "   c79eae5..d9f6ce4  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git add requirements.txt\n",
    "!git commit -m \"Add requirements for resume screening app\"\n",
    "!git push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d684c57e-83d8-489f-8c60-9437eeff458a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
